{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import nps_chat, gutenberg, brown"
      ],
      "metadata": {
        "id": "ziI3OoW6OskX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('nps_chat')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "id": "vBR0ULskqppJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
        "print(chatroom[123])"
      ],
      "metadata": {
        "id": "qiuowl7TO-5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze data\n",
        "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
        "print(emma)\n",
        "print(emma.concordance(\"surprize\"))\n",
        "\n",
        "emma1 = nltk.Text(nltk.corpus.brown.words('cr03'))\n",
        "print(emma1)"
      ],
      "metadata": {
        "id": "D2rZIVX8O1M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYAl7JiQOe2y"
      },
      "outputs": [],
      "source": [
        "# analyze corpus\n",
        "for fileid in brown.fileids():\n",
        "    num_chars = len(brown.raw(fileid))\n",
        "    num_words = len(brown.words(fileid))\n",
        "    num_sents = len(brown.sents(fileid))\n",
        "    num_vocab = len(set(w.lower() for w in brown.words(fileid)))\n",
        "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
      ]
    }
  ]
}